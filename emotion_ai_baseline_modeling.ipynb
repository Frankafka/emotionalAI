{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EmotionalAI: Baseline Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis by Frank Flavell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models\n",
    "\n",
    "With cleaned data, I ran a few baseline models with a few simple variations to determine my starting point for improvement.  I will use these baseline models to help me see which features currently have a significant impact on the model's predictive power and to determine what feature engineering could be useful.\n",
    "\n",
    "### Target\n",
    "* Emotion: 0: No emotion, 1: Anger, 2: Disgust, 3: Fear, 4: Happiness, 5: Sadness, 6: Surprise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents<span id=\"0\"></span>\n",
    "\n",
    "1. [**Train/ Test Split**](#1)\n",
    "<br/><br/>\n",
    "2. [**Logistic Regression**](#2)\n",
    "<br/><br/>\n",
    "3. [**Naive Bayes**](#3)\n",
    "<br/><br/>\n",
    "4. [**Support Vector Machine**](#4)\n",
    "<br/><br/>\n",
    "5. [**Random Forest**](#5)\n",
    "<br/><br/>\n",
    "6. [**Initial Findings**](#6)\n",
    "    * Class Imbalance\n",
    "    * Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#Pre-Processing\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#Train/Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Modeling Processing Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#Evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data/dialogue_master.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>topic</th>\n",
       "      <th>emotion</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>the kitchen stinks.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>i will throw out the garbage.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>so dick, how about getting some coffee for ton...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>coffee? i do not honestly like that kind of st...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>come on, you can at least try a little, beside...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dialogue  topic  emotion  type\n",
       "0                                the kitchen stinks.      1        2     3\n",
       "1                      i will throw out the garbage.      1        0     4\n",
       "2  so dick, how about getting some coffee for ton...      1        4     3\n",
       "3  coffee? i do not honestly like that kind of st...      1        2     4\n",
       "4  come on, you can at least try a little, beside...      1        0     3"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102980, 4)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 102980 entries, 0 to 102979\n",
      "Data columns (total 4 columns):\n",
      "dialogue    102980 non-null object\n",
      "topic       102980 non-null int64\n",
      "emotion     102980 non-null int64\n",
      "type        102980 non-null int64\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"1\"></span>1. Train/ Test Split\n",
    "#### [Return Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.dialogue\n",
    "y = df.emotion\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['No emotion', 'Anger', 'Disgust', 'Fear', 'Happiness', 'Sadness', 'Surprise']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"2\"></span>2. Logistic Regression Baseline\n",
    "#### [Return Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8474655272868518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  No emotion       0.88      0.95      0.91     21424\n",
      "       Anger       0.46      0.16      0.24       259\n",
      "     Disgust       0.40      0.18      0.25        79\n",
      "        Fear       0.40      0.04      0.08        46\n",
      "   Happiness       0.59      0.39      0.47      3259\n",
      "     Sadness       0.30      0.14      0.19       259\n",
      "    Surprise       0.50      0.27      0.35       419\n",
      "\n",
      "    accuracy                           0.85     25745\n",
      "   macro avg       0.50      0.30      0.36     25745\n",
      "weighted avg       0.82      0.85      0.83     25745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=emotions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"3\"></span>3. Naive Bayes Baseline\n",
    "#### [Return Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8377937463585162\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  No emotion       0.84      1.00      0.91     21424\n",
      "       Anger       0.00      0.00      0.00       259\n",
      "     Disgust       0.00      0.00      0.00        79\n",
      "        Fear       0.00      0.00      0.00        46\n",
      "   Happiness       0.78      0.06      0.11      3259\n",
      "     Sadness       0.00      0.00      0.00       259\n",
      "    Surprise       0.00      0.00      0.00       419\n",
      "\n",
      "    accuracy                           0.84     25745\n",
      "   macro avg       0.23      0.15      0.15     25745\n",
      "weighted avg       0.80      0.84      0.77     25745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=emotions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"4\"></span>4. Support Vector Machine\n",
    "#### [Return Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8363177315983686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  No emotion       0.84      0.99      0.91     21424\n",
      "       Anger       0.00      0.00      0.00       259\n",
      "     Disgust       0.00      0.00      0.00        79\n",
      "        Fear       0.00      0.00      0.00        46\n",
      "   Happiness       0.63      0.08      0.14      3259\n",
      "     Sadness       0.00      0.00      0.00       259\n",
      "    Surprise       0.00      0.00      0.00       419\n",
      "\n",
      "    accuracy                           0.84     25745\n",
      "   macro avg       0.21      0.15      0.15     25745\n",
      "weighted avg       0.78      0.84      0.78     25745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=emotions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"5\"></span>5. Random Forest Baseline\n",
    "#### [Return Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8321615847737425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  No emotion       0.83      1.00      0.91     21424\n",
      "       Anger       0.00      0.00      0.00       259\n",
      "     Disgust       0.00      0.00      0.00        79\n",
      "        Fear       0.00      0.00      0.00        46\n",
      "   Happiness       0.00      0.00      0.00      3259\n",
      "     Sadness       0.00      0.00      0.00       259\n",
      "    Surprise       0.00      0.00      0.00       419\n",
      "\n",
      "    accuracy                           0.83     25745\n",
      "   macro avg       0.12      0.14      0.13     25745\n",
      "weighted avg       0.69      0.83      0.76     25745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdf = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', RandomForestClassifier(n_estimators=100, max_depth= 5)),\n",
    "               ])\n",
    "rdf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rdf.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=emotions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"6\"></span>6. Initial Findings\n",
    "#### [Return Contents](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Imbalance\n",
    "\n",
    "Clearly there is a huge class imbalance issue.  The 'No Emotion' classification has far more instances than the other classifications.  A semi-decent accuracy at predicting 'No Emotion' is hiding the fact that all models did a terrible job at classifying actual emotions.  I will need to take a look at this class imbalance in EDA and address it in the next round of modeling.\n",
    "\n",
    "#### Feature Engineering\n",
    "\n",
    "Also it's clear that the cleaned dialogue itself doesn't provide enough information for these models to effectively classify emotions.  This opens up opportunities for feature engineering to see what new features could capture the meaning behind the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
